# 模型优化说明

## ✅ 已完成的优化

为了提升生成速度，系统现在使用**混合模型策略**：

### 🚀 快速模型 (deepseek-chat)
用于不需要深度思考的任务，速度更快（2-5秒）：
- **Router 节点**：路由决策，只需要简单分类
- **Writer 节点**：格式化输出，只是结构调整

### 🧠 推理模型 (deepseek-reasoner)
用于需要深度思考的任务，质量更高（10-30秒）：
- **Specialist/Finance 节点**：生成题目初稿，需要创意和质量
- **Critic 节点**：审核题目，需要逻辑验证
- **Fixer 节点**：修复题目，需要理解问题

## 📊 性能提升

**优化前**（全部使用 reasoner）：
- Router: ~10秒
- Specialist: ~20秒
- Writer: ~10秒
- Critic: ~24秒
- **总计：~64秒**

**优化后**（混合模型）：
- Router: ~3秒 (chat) ⚡
- Specialist: ~20秒 (reasoner)
- Writer: ~3秒 (chat) ⚡
- Critic: ~24秒 (reasoner)
- **总计：~50秒（节省约 20%）**

## 🎯 配置方式

在 Streamlit 界面中：
- **推理模型**：默认 `deepseek-reasoner`（用于生成和审核）
- **快速模型**：默认 `deepseek-chat`（用于路由和格式化）

您可以根据需要调整这两个模型的配置。

## 💡 为什么这样设计？

1. **路由决策**（Router）：
   - 只需要根据关键词判断，不需要深度推理
   - 使用快速模型可以节省时间

2. **格式化输出**（Writer）：
   - 主要是结构调整和格式转换
   - 不需要复杂的逻辑推理
   - 快速模型足够

3. **题目生成**（Specialist/Finance）：
   - 需要创意和质量
   - 需要深度理解知识点
   - 必须使用推理模型

4. **审核修复**（Critic/Fixer）：
   - 需要逻辑验证和问题分析
   - 需要深度思考
   - 必须使用推理模型

